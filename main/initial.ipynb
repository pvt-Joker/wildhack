{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "98bf2f11-e902-489a-a6a7-746a6ddb63b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/alexkon/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import vaex as vx\n",
    "import sys\n",
    "import re\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "import itertools\n",
    "from tqdm.contrib.itertools import product\n",
    "import pymorphy2\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "41783eef-cccd-4890-b1ab-c5ea1b12ccc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymorphy2-dicts-ru in /opt/anaconda3/lib/python3.8/site-packages (2.4.417127.4579844)\n"
     ]
    }
   ],
   "source": [
    "#!pip3 install vaex\n",
    "#!pip3 install autocorrect\n",
    "#!pip3 install fuzzywuzzy\n",
    "#!pip3 install python-Levenshtein\n",
    "#!pip3 install pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f8b286-460b-4060-8fec-97eb2347b716",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "data = vx.open('history_small.csv')\n",
    "data.__delitem__('weekday')\n",
    "data.__delitem__('time')\n",
    "data.__delitem__('Unnamed: 0')\n",
    "data = data[['UQ', 'cnt']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1de5b314-3d4c-4f91-8fa2-927821b58f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3bcfb37-48ef-4ab1-b3e3-80475e1bab45",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna(column_names=['UQ'])\n",
    "data['UQ'] = data['UQ'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2148009-947f-4a7a-a505-b57673868228",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = list(data['UQ'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f541ce73-d785-4fca-bc89-431cda370ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d41ff8d-9feb-4351-ad04-cd8eb82db99c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.6 s, sys: 9.82 s, total: 22.4 s\n",
      "Wall time: 45.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "key_source = data['UQ'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "75f47f6d-286f-418a-9c18-4f0af9bc6276",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15148855/15148855 [00:55<00:00, 271875.60it/s]\n"
     ]
    }
   ],
   "source": [
    "word = {}\n",
    "for i in tqdm(range(len(source))):\n",
    "    string = re.sub(\"[^0-9a-zа-я]+\", \" \", source[i])\n",
    "    x = string.split(' ')\n",
    "    for j in x:\n",
    "        if j in word.keys():\n",
    "            word[j] +=1\n",
    "        else:\n",
    "            word[j] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "215c9e28-a74e-4a71-822c-6315903782b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2734432, 2)\n",
      "(2551276, 2)\n"
     ]
    }
   ],
   "source": [
    "words = pd.DataFrame.from_dict(word, orient='index').reset_index()\n",
    "words.rename({0:'num'}, axis=1, inplace=True)\n",
    "print(words.shape)\n",
    "words = words[words['index'].str.contains(r'[a-zа-я]')]\n",
    "print(words.shape)\n",
    "words.sort_values(by='num', ascending=False, inplace=True)\n",
    "words_nostop = words[~words['index'].isin(stop_words)]\n",
    "top_words = words_nostop[words_nostop.num>=5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "81426432-d679-48a4-ae30-dd04f231228b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2551125/2551125 [06:47<00:00, 6254.06it/s]\n"
     ]
    }
   ],
   "source": [
    "POS_list = ['ADJF']\n",
    "wd_list = list(words_nostop['index'])\n",
    "norm_words = {}\n",
    "for i in tqdm(range(len(wd_list))):\n",
    "    p = morph.parse(wd_list[i])\n",
    "    s = set(map(lambda l: l.normal_form, p))\n",
    "    st = set(map(lambda l: l.tag.POS, p))\n",
    "    if len(s) == 1:\n",
    "        norm_words[wd_list[i]] = p[0].normal_form\n",
    "    elif st == {'ADJF'}:\n",
    "        norm_words[wd_list[i]] = p[0].normal_form\n",
    "    else:\n",
    "        norm_words[wd_list[i]] = wd_list[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "484a3acb-e9fa-4f72-bcb0-8adb8ae58518",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_clear = pd.DataFrame.from_dict(norm_words, orient='index', columns = ['word']).reset_index()\n",
    "words_clear = words_clear.merge(words_nostop, how='left', on='index')\n",
    "words_clear = words_clear.groupby('word').sum().reset_index().sort_values(by='num', ascending=False)\n",
    "words_clear.rename({'word': 'index'}, axis=1, inplace=True)\n",
    "words_clear = words_clear.loc[words_clear.num>=words_clear.num.quantile(0.95)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70832be5-76af-4680-bb6b-2230ddbe9fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spellru = Speller(lang='ru')\n",
    "# spellen = Speller(lang='en')\n",
    "\n",
    "# patternen = re.compile(\"[a-z]+\")\n",
    "# patternru = re.compile(\"[а-я]+\")\n",
    "\n",
    "# misswords = list(word.keys())\n",
    "# correction = {}\n",
    "# for x in tqdm(range(len(misswords))):\n",
    "#     if len(misswords[x])<3:\n",
    "#         correction[misswords[x]] = misswords[x]\n",
    "#         continue\n",
    "#     if patternen.fullmatch(misswords[x]):\n",
    "#         correction[misswords[x]] = spellen(misswords[x])\n",
    "#     elif patternru.fullmatch(misswords[x]):\n",
    "#         correction[misswords[x]] = spellru(misswords[x])\n",
    "#     else:\n",
    "#         correction[misswords[x]] = misswords[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7767cb67-7bb2-4ea4-b30c-d91d01666692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spellru = SpellChecker(language='ru')\n",
    "# misswords = list(word.keys())\n",
    "# correction = {}\n",
    "# misspelled = spellru.unknown(misswords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43146215-f949-4de8-ae2f-271c2ff36b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_doc = TextBlob(' '.join(list(misspelled)))\n",
    "# result = new_doc.correct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbe4bc0-b9b8-4507-bb4e-61d1ab4d4e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_dict = {}\n",
    "# word_list = list(word.keys())\n",
    "# tops = list(top_words['index'])\n",
    "# for j in tqdm(range(len(word_list))):\n",
    "#     word_input = word_list[j]\n",
    "#     temp = {}\n",
    "#     for i in range(len(tops)):\n",
    "#         rat = fuzz.ratio(word_input, tops[i])\n",
    "#         if rat>50:\n",
    "#             temp[tops[i]] = rat\n",
    "#     compare = pd.DataFrame.from_dict(temp, orient='index').reset_index()\n",
    "#     compare.rename({0: 'simi'}, axis=1, inplace=True)\n",
    "#     compare = compare.merge(top_words, how='left', on='index')\n",
    "#     compare['metric'] = (0.01*compare['simi'])*np.log(compare['num'])\n",
    "#     compare.sort_values(by='metric', ascending=False, inplace=True)\n",
    "#     key_word = compare['index'].iloc[0]\n",
    "#     word_dict[word_input] = key_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "9d7205df-c515-4b4f-94e7-1af8cc3d5024",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15148855/15148855 [01:38<00:00, 154013.78it/s]\n"
     ]
    }
   ],
   "source": [
    "double_words = {}\n",
    "triple_words = {}\n",
    "for i in tqdm(range(len(source))):\n",
    "    x = key_source[i].as_py().split(' ')\n",
    "    s = ''\n",
    "    if (len(x))>=2:\n",
    "        if not any(list(map(lambda w: w in stop_words,x[:2]))):\n",
    "            s = ' '.join(x[:2])\n",
    "            if s in double_words.keys():\n",
    "                double_words[s] += 1\n",
    "            else:\n",
    "                double_words[s] = 1\n",
    "        s= ''\n",
    "        if len(x)>2:\n",
    "            s = ' '.join(x[:3])\n",
    "            if s in triple_words.keys():\n",
    "                triple_words[s] += 1\n",
    "            else:\n",
    "                triple_words[s] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "a2ade7c5-45b5-4523-a54c-fb74502a31a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "double_words = pd.DataFrame.from_dict(double_words, orient='index').reset_index()\n",
    "double_words.rename({0:'num'}, axis=1, inplace=True)\n",
    "double_words.sort_values(by='num', ascending=False, inplace=True)\n",
    "double_words = double_words[double_words['num']>= 50]\n",
    "\n",
    "triple_words = pd.DataFrame.from_dict(triple_words, orient='index').reset_index()\n",
    "triple_words.rename({0:'num'}, axis=1, inplace=True)\n",
    "triple_words.sort_values(by='num', ascending=False, inplace=True)\n",
    "triple_words = triple_words[triple_words['num']>= 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "100f3dea-c55e-4b08-b2b2-3513665219e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "zz = double_words.copy()\n",
    "zz['index_modi'] = zz['index'].str.split(' ').apply(lambda x: ' '.join(sorted(x)))\n",
    "temp = zz.groupby('index_modi').sum().reset_index()\n",
    "zz.drop_duplicates(subset=['index_modi'], inplace=True)\n",
    "zz = temp.merge(zz[['index', 'index_modi']], how='left', on='index_modi')\n",
    "double_words = zz[['index', 'num']].sort_values(by='num')\n",
    "\n",
    "\n",
    "zz = triple_words.copy()\n",
    "zz['index_modi'] = zz['index'].str.split(' ').apply(lambda x: ' '.join(sorted(x)))\n",
    "temp = zz.groupby('index_modi').sum().reset_index()\n",
    "zz.drop_duplicates(subset=['index_modi'], inplace=True)\n",
    "zz = temp.merge(zz[['index', 'index_modi']], how='left', on='index_modi')\n",
    "triple_words = zz[['index', 'num']].sort_values(by='num')\n",
    "\n",
    "del zz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "2238945e-9fe7-43a1-8f2f-f32990eeb71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-458-1021644846b1>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  words_clear['source'] = 'words_clear'\n",
      "<ipython-input-458-1021644846b1>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  words_nostop['source'] = 'words_nostop'\n"
     ]
    }
   ],
   "source": [
    "words_clear['source'] = 'words_clear'\n",
    "double_words['source'] = 'double_words'\n",
    "triple_words['source'] = 'triple_words'\n",
    "words_nostop['source'] = 'words_nostop'\n",
    "total_df = pd.concat([words_clear, double_words, triple_words, words_nostop], ignore_index=True)\n",
    "total_df.to_csv('data_source.csv')\n",
    "dd = pd.DataFrame(source)\n",
    "dd.to_csv('source_req.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c442561-daf4-49f1-9d58-b70801764556",
   "metadata": {},
   "source": [
    "### Расчет для тегов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "75e708db-9d3a-4159-8dfd-a02cb0b33920",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stops(x):\n",
    "    x = x.split(' ')\n",
    "    if x[-1] in stop_words:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "1088f90b-7673-44bf-9cc0-a5bbe2abd0c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 123430/123430 [00:00<00:00, 379903.84it/s]\n"
     ]
    }
   ],
   "source": [
    "word_phrase = 'резиновый'\n",
    "word_phrase = word_phrase.split(' ')\n",
    "sign = 0\n",
    "word_list = list(words_clear['index'])\n",
    "key_words = []\n",
    "for word_input in word_phrase:\n",
    "    if word_input in stop_words:\n",
    "        if word_input == 'без':\n",
    "            sign='-'\n",
    "            continue\n",
    "        else:\n",
    "            sign='+'\n",
    "            continue\n",
    "    temp = {}\n",
    "    for i in tqdm(range(len(word_list))):\n",
    "        rat = fuzz.ratio(word_input, word_list[i])\n",
    "        if rat>50:\n",
    "            temp[word_list[i]] = rat\n",
    "    compare = pd.DataFrame.from_dict(temp, orient='index').reset_index()\n",
    "    compare.rename({0: 'simi'}, axis=1, inplace=True)\n",
    "    compare = compare.merge(words_clear, how='left', on='index')\n",
    "    compare['metric'] = (0.01*compare['simi'])*np.log(compare['num'])\n",
    "    compare.sort_values(by='metric', ascending=False, inplace=True)\n",
    "    key_words.append(compare['index'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "92769fb9-95ce-4552-8e8f-362fefcc2728",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15148855/15148855 [00:06<00:00, 2172460.33it/s]\n"
     ]
    }
   ],
   "source": [
    "using = {}\n",
    "top_head_dict = {1:10, 2:6, 3:3, 4:3}\n",
    "for key_word in key_words:   \n",
    "    temp = {}\n",
    "    for i in tqdm(range(len(source))):\n",
    "        if key_word in source[i]:\n",
    "            x = source[i].split(' ')\n",
    "            for j in x:\n",
    "                if j in temp.keys():\n",
    "                    temp[j] +=1\n",
    "                else:\n",
    "                    temp[j] = 1\n",
    "    most_used = pd.DataFrame.from_dict(temp, orient='index').reset_index()\n",
    "    most_used.rename({0:'use_num'}, axis=1, inplace=True)\n",
    "    most_used.sort_values(by='use_num', ascending=False, inplace=True)\n",
    "    most_used = most_used[~most_used['index'].isin(stop_words)]\n",
    "    most_used = most_used.head(top_head_dict[len(key_words)])\n",
    "    most_used = most_used.merge(words_nostop, how='left', on='index')\n",
    "    using[key_word] = most_used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "59bb777b-a3fb-46fb-8306-347551c6761a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efd7ccb34fb44f4d9203032e75127f03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c76d6a58404430e93b04f23538156f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "key_list = []\n",
    "weight_list = []\n",
    "matching_list = {}\n",
    "metric_list = {}\n",
    "match_size = 1\n",
    "for key_word in using.keys():  \n",
    "    key_list.append(list(using[key_word]['index']))\n",
    "    weight_list.append(list(using[key_word]['use_num']))\n",
    "    match_size *= len(using[key_word])\n",
    "weights = list(product(*weight_list))\n",
    "max_weight = np.max(weights)\n",
    "for i in range(len(weights)):\n",
    "    weights[i] = np.sum(list(weights[i]))\n",
    "step = 0\n",
    "for elem in product(*key_list):\n",
    "    cur_weight = 100*weights[step]/max_weight\n",
    "    step+=1\n",
    "    for row in double_words.itertuples():\n",
    "        t = fuzz.token_sort_ratio(row[1], str(' '.join(elem)))\n",
    "        if t>50:\n",
    "            metr = t*cur_weight*np.log(np.log(row[2]))\n",
    "            if row[1] in matching_list.keys():\n",
    "                if metr>metric_list[row[1]]:\n",
    "                    metric_list[row[1]] = metr\n",
    "            else:\n",
    "                matching_list[row[1]] = 1\n",
    "                metric_list[row[1]] = metr\n",
    "    for row in triple_words.itertuples():\n",
    "        t = fuzz.token_sort_ratio(row[1], str(' '.join(elem)))\n",
    "        if t>50:\n",
    "            metr = t*cur_weight*np.log(np.log(row[2]))\n",
    "            if row[1] in matching_list.keys():\n",
    "                if metr>metric_list[row[1]]:\n",
    "                    metric_list[row[1]] = metr\n",
    "            else:\n",
    "                matching_list[row[1]] = 1\n",
    "                metric_list[row[1]] = metr\n",
    "for x in matching_list.keys():\n",
    "    matching_list[x] = matching_list[x]*metric_list[x]\n",
    "matches = pd.DataFrame.from_dict(matching_list, orient='index').reset_index()\n",
    "matches.rename({0:'num'}, axis=1, inplace=True)\n",
    "matches.sort_values(by='num',  ascending=False, inplace=True)\n",
    "matches = matches.head(50)\n",
    "matches['flag'] = matches['index'].apply(stops)\n",
    "matches = matches.loc[matches.flag == 0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "ac45be3c-e807-45ba-84c4-db594b646d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Запрос:\n",
      "резиновый\n",
      "\n",
      "Теги:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['резиновые сапоги',\n",
       " 'резиновый коврик',\n",
       " 'мяч резиновый',\n",
       " 'новый год',\n",
       " 'резиновый член',\n",
       " 'резиновые тапочки',\n",
       " 'протеиновый батончик',\n",
       " 'перчатки резиновые',\n",
       " 'резиновые ботинки',\n",
       " 'тапки резиновые']"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Запрос:')\n",
    "print(' '.join(word_phrase))\n",
    "print('\\nТеги:')\n",
    "list(matches.head(10)['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7538e9-f048-46e9-a426-13218ad492a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
