{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5a9c8e-f325-4562-83a4-6772283634d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import vaex as vx\n",
    "import sys\n",
    "import re\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "import itertools\n",
    "from tqdm.contrib.itertools import product\n",
    "import pymorphy2\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5886a644-5552-4c7c-8bb0-782e7dd89fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install vaex\n",
    "#!pip3 install autocorrect\n",
    "#!pip3 install fuzzywuzzy\n",
    "#!pip3 install python-Levenshtein\n",
    "#!pip3 install pymorphy2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f159781-9ef6-4cda-b1dd-54c285b22804",
   "metadata": {},
   "source": [
    "### Чтение данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c588ce-ba20-457d-b05b-7ea1fb50613d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "data = vx.open('history_small.csv')\n",
    "data.__delitem__('weekday')\n",
    "data.__delitem__('time')\n",
    "data.__delitem__('Unnamed: 0')\n",
    "data = data[['UQ', 'cnt']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16adcc05-e34e-4d74-82f8-f8182e982c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683eb598-aa1f-449e-83f7-81a4452b6a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna(column_names=['UQ'])\n",
    "data['UQ'] = data['UQ'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3c5dfe-904a-4001-8493-234ef25fb1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = list(data['UQ'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c684ecf-b0aa-4d45-aba2-d179ecdd36ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570c5f07-35d4-4c2a-bcd4-1d853a6b7a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "key_source = data['UQ'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c0e092-b8c1-41d6-8d4d-980200b4c06f",
   "metadata": {},
   "source": [
    "### Обработка входных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b884de-54c6-4455-bb10-366532e1b108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выбор уникальных слов и подсчет количества использований, замена всех технических символов,\n",
    "# очистка от всех слов, не содержащих буквы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed5cf52-f771-4053-9c48-48f2adb309d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "word = {}\n",
    "for i in tqdm(range(len(source))):\n",
    "    string = re.sub(\"[^0-9a-zа-я]+\", \" \", source[i])\n",
    "    x = string.split(' ')\n",
    "    for j in x:\n",
    "        if j in word.keys():\n",
    "            word[j] +=1\n",
    "        else:\n",
    "            word[j] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736051a6-9420-4de5-8958-303adc8688ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отбор слов, содержащих только быквы и формирования списка наиболее используемых слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8102fdeb-bb34-4a25-a302-a3c86a12de52",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = pd.DataFrame.from_dict(word, orient='index').reset_index()\n",
    "words.rename({0:'num'}, axis=1, inplace=True)\n",
    "print(words.shape)\n",
    "words = words[words['index'].str.contains(r'[a-zа-я]')]\n",
    "print(words.shape)\n",
    "words.sort_values(by='num', ascending=False, inplace=True)\n",
    "words_nostop = words[~words['index'].isin(stop_words)]\n",
    "top_words = words_nostop[words_nostop.num>=5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396e70f8-93cf-4da9-8f94-afb38c3ab3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Приведение прилагательных и существительных к нормализованной форме, где это возможно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398cfde8-e079-44a9-805a-e4ff76beb967",
   "metadata": {},
   "outputs": [],
   "source": [
    "POS_list = ['ADJF']\n",
    "wd_list = list(words_nostop['index'])\n",
    "norm_words = {}\n",
    "for i in tqdm(range(len(wd_list))):\n",
    "    p = morph.parse(wd_list[i])\n",
    "    s = set(map(lambda l: l.normal_form, p))\n",
    "    st = set(map(lambda l: l.tag.POS, p))\n",
    "    if len(s) == 1:\n",
    "        norm_words[wd_list[i]] = p[0].normal_form\n",
    "    elif st == {'ADJF'}:\n",
    "        norm_words[wd_list[i]] = p[0].normal_form\n",
    "    else:\n",
    "        norm_words[wd_list[i]] = wd_list[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747c3a55-01fb-49e4-97bb-883b37d91579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание чистого датасета ключевых слов для формирования тэговых запросов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d057ed-6fe1-4850-9fc9-2ed2c0595476",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_clear = pd.DataFrame.from_dict(norm_words, orient='index', columns = ['word']).reset_index()\n",
    "words_clear = words_clear.merge(words_nostop, how='left', on='index')\n",
    "words_clear = words_clear.groupby('word').sum().reset_index().sort_values(by='num', ascending=False)\n",
    "words_clear.rename({'word': 'index'}, axis=1, inplace=True)\n",
    "words_clear = words_clear.loc[words_clear.num>=words_clear.num.quantile(0.95)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae25f99-d86b-45e9-83a5-7ba3db528615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Формирование списков наиболее используемых словосочетанй из 2 и 3 слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f38ffd8-e0da-4741-9cc7-5e2a56669b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "double_words = {}\n",
    "triple_words = {}\n",
    "for i in tqdm(range(len(source))):\n",
    "    x = key_source[i].as_py().split(' ')\n",
    "    s = ''\n",
    "    if (len(x))>=2:\n",
    "        if not any(list(map(lambda w: w in stop_words,x[:2]))):\n",
    "            s = ' '.join(x[:2])\n",
    "            if s in double_words.keys():\n",
    "                double_words[s] += 1\n",
    "            else:\n",
    "                double_words[s] = 1\n",
    "        s= ''\n",
    "        if len(x)>2:\n",
    "            s = ' '.join(x[:3])\n",
    "            if s in triple_words.keys():\n",
    "                triple_words[s] += 1\n",
    "            else:\n",
    "                triple_words[s] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f5d7f7-b7e4-474c-9341-c6f76c1a50b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "double_words = pd.DataFrame.from_dict(double_words, orient='index').reset_index()\n",
    "double_words.rename({0:'num'}, axis=1, inplace=True)\n",
    "double_words.sort_values(by='num', ascending=False, inplace=True)\n",
    "double_words = double_words[double_words['num']>= 50]\n",
    "\n",
    "triple_words = pd.DataFrame.from_dict(triple_words, orient='index').reset_index()\n",
    "triple_words.rename({0:'num'}, axis=1, inplace=True)\n",
    "triple_words.sort_values(by='num', ascending=False, inplace=True)\n",
    "triple_words = triple_words[triple_words['num']>= 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e57018-1faa-4bd8-b8e7-d05e21e741d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Очистка используемых словосочетаний, объединение словосочетаний, отличающихся только расстановкой слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffe974b-1288-4849-b6c7-e1f01cb5ef61",
   "metadata": {},
   "outputs": [],
   "source": [
    "zz = double_words.copy()\n",
    "zz['index_modi'] = zz['index'].str.split(' ').apply(lambda x: ' '.join(sorted(x)))\n",
    "temp = zz.groupby('index_modi').sum().reset_index()\n",
    "zz.drop_duplicates(subset=['index_modi'], inplace=True)\n",
    "zz = temp.merge(zz[['index', 'index_modi']], how='left', on='index_modi')\n",
    "double_words = zz[['index', 'num']].sort_values(by='num')\n",
    "\n",
    "\n",
    "zz = triple_words.copy()\n",
    "zz['index_modi'] = zz['index'].str.split(' ').apply(lambda x: ' '.join(sorted(x)))\n",
    "temp = zz.groupby('index_modi').sum().reset_index()\n",
    "zz.drop_duplicates(subset=['index_modi'], inplace=True)\n",
    "zz = temp.merge(zz[['index', 'index_modi']], how='left', on='index_modi')\n",
    "triple_words = zz[['index', 'num']].sort_values(by='num')\n",
    "\n",
    "del zz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef23fa3-69c6-4d43-a515-26dcf2d91b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохранение данных для перехода к этапу расчета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729f2aec-c055-4e16-8acf-4436440b08d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_clear['source'] = 'words_clear'\n",
    "double_words['source'] = 'double_words'\n",
    "triple_words['source'] = 'triple_words'\n",
    "words_nostop['source'] = 'words_nostop'\n",
    "total_df = pd.concat([words_clear, double_words, triple_words, words_nostop], ignore_index=True)\n",
    "dd = pd.DataFrame(source)\n",
    "dd = to_csv('source_req.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
